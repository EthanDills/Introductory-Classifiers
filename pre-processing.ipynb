{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d81448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3fc2b",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Some of our data is categorical feature data. This won't work for our models relying on numerical data.\n",
    "Therefore we need to encode these string features into some kind of numerical value.\n",
    "\n",
    "For string data that seems to be ordered, we'll use **[ordinal encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder)** to convey that this information has an order to it.\n",
    "\n",
    "For string data that doesn't seem to be ordered, we'll use **[one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)** so the model doesn't interpret these features as having an order.\n",
    "\n",
    "* Note that OneHotEncoder() by default sorts String categorical features alphabetically\n",
    "\n",
    "**ordered string features: f3, f11**\n",
    "\n",
    "**unordered string features: f1, f5, f7, f9, f16** (some of these could technically be considered ordered... but I didn't think they were)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb0664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     f1_Bird  f1_Cat  f1_Dog   f2  f4  f5_Blue  f5_Green  f5_Red   f6  \\\n",
      "0        0.0     1.0     0.0  0.6   4      1.0       0.0     0.0 -2.1   \n",
      "1        0.0     1.0     0.0 -0.6   2      0.0       1.0     0.0 -2.2   \n",
      "2        0.0     0.0     1.0 -0.6   3      0.0       0.0     1.0 -1.4   \n",
      "3        0.0     1.0     0.0  0.7   1      0.0       1.0     0.0 -1.9   \n",
      "4        0.0     0.0     1.0  1.4   4      0.0       0.0     1.0 -2.4   \n",
      "..       ...     ...     ...  ...  ..      ...       ...     ...  ...   \n",
      "995      0.0     1.0     0.0 -0.0   1      0.0       1.0     0.0 -1.1   \n",
      "996      0.0     1.0     0.0 -0.6   3      1.0       0.0     0.0 -1.1   \n",
      "997      0.0     0.0     1.0 -0.3   4      0.0       1.0     0.0 -2.9   \n",
      "998      0.0     0.0     1.0  1.5   4      1.0       0.0     0.0 -2.2   \n",
      "999      1.0     0.0     0.0 -1.6   2      0.0       0.0     1.0 -1.7   \n",
      "\n",
      "     f7_Maybe  ...  f10  f12  f13  f14  f15  f17  f18  f19  f20  target  \n",
      "0         0.0  ... -0.8  6.6  0.5  1.2    1 -0.0 -1.7 -1.5  1.2       0  \n",
      "1         1.0  ...  0.3  3.9 -0.1 -0.1    1 -0.2 -1.6 -0.3  2.4       1  \n",
      "2         1.0  ... -0.5  3.4  0.6 -0.1    0 -0.7  0.9  0.1  2.4       1  \n",
      "3         0.0  ... -0.7  5.0  1.5  0.7    1  0.5 -2.0  1.0  5.0       1  \n",
      "4         0.0  ... -0.1  4.7 -0.2 -1.1    0 -1.5  1.0  0.5  2.9       1  \n",
      "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...  \n",
      "995       0.0  ... -1.2  6.6 -0.3  0.8    1  1.9  0.9 -2.4  2.9       0  \n",
      "996       0.0  ... -2.3  4.4  1.8 -0.6    0  0.2 -0.6 -0.0  4.8       0  \n",
      "997       0.0  ... -1.0  4.4  0.6  2.0    0 -0.7 -1.8  0.5  3.0       0  \n",
      "998       1.0  ... -0.2  6.6 -0.6  0.1    0 -0.2  1.9  0.5  2.4       0  \n",
      "999       0.0  ...  2.6  5.7  0.6 -1.2    0  0.4 -0.8  0.6  4.6       1  \n",
      "\n",
      "[1000 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_for_students.csv\")\n",
    "test = pd.read_csv(\"test_for_students.csv\")\n",
    "\n",
    "\n",
    "# manually doing ordinal encoding for f3, f11\n",
    "f3_mapping = {\"Low\":0, \"Medium\":1, \"High\":2}\n",
    "train[\"f3\"] = train[\"f3\"].map(f3_mapping)\n",
    "# print(train[\"f3\"])\n",
    "\n",
    "f11_mapping = {\"Basic\":0, \"Standard\":1, \"Premium\":2}\n",
    "train[\"f11\"] = train[\"f11\"].map(f11_mapping)\n",
    "# print(train[\"f11\"])\n",
    "\n",
    "\n",
    "# Implementing one-hot encoding with sklearn for f1, f5, f7, f9, f16\n",
    "# NOTE: for however many categories there are in a feature (for example, f1 has 3 categories: Bird, Cat, Dog),\n",
    "#  We'll need to add this amount of columns. For example, f1 gets turned into 3 feature columns after one-hot encoding\n",
    "one_hot = OneHotEncoder(sparse_output = False)\n",
    "    \n",
    "# print(train[\"f1\"])\n",
    "\n",
    "\n",
    "# encoding f1\n",
    "one_hot.fit(train[[\"f1\"]])\n",
    "f1_encode_train = one_hot.transform(train[[\"f1\"]])\n",
    "f1_encode_test = one_hot.transform(test[[\"f1\"]])\n",
    "# f1_Bird_col = [f1_encode[i][0] for i in range(len(f1_encode))]\n",
    "# print(f1_Bird_col)\n",
    "train.insert(1, \"f1_Bird\", [f1_encode_train[i][0] for i in range(len(f1_encode_train))])\n",
    "train.insert(2, \"f1_Cat\", [f1_encode_train[i][1] for i in range(len(f1_encode_train))])\n",
    "train.insert(3, \"f1_Dog\", [f1_encode_train[i][2] for i in range(len(f1_encode_train))])\n",
    "test.insert(1, \"f1_Bird\", [f1_encode_test[i][0] for i in range(len(f1_encode_test))])\n",
    "test.insert(2, \"f1_Cat\", [f1_encode_test[i][1] for i in range(len(f1_encode_test))])\n",
    "test.insert(3, \"f1_Dog\", [f1_encode_test[i][2] for i in range(len(f1_encode_test))])\n",
    "\n",
    "# encoding f5\n",
    "# train[\"f5\"] is now the eighth column\n",
    "one_hot.fit(train[[\"f5\"]])\n",
    "f5_encode_train = one_hot.transform(train[[\"f5\"]])\n",
    "f5_encode_test = one_hot.transform(test[[\"f5\"]])\n",
    "\n",
    "train.insert(8, \"f5_Blue\", [f5_encode_train[i][0] for i in range(len(f5_encode_train))])\n",
    "train.insert(9, \"f5_Green\", [f5_encode_train[i][1] for i in range(len(f5_encode_train))])\n",
    "train.insert(10, \"f5_Red\", [f5_encode_train[i][2] for i in range(len(f5_encode_train))])    \n",
    "test.insert(8, \"f5_Blue\", [f5_encode_test[i][0] for i in range(len(f5_encode_test))])\n",
    "test.insert(9, \"f5_Green\", [f5_encode_test[i][1] for i in range(len(f5_encode_test))])\n",
    "test.insert(10, \"f5_Red\", [f5_encode_test[i][2] for i in range(len(f5_encode_test))])    \n",
    "\n",
    "# encoding f7\n",
    "# train[\"f7\"] is now the 13th column\n",
    "one_hot.fit(train[[\"f7\"]]) \n",
    "f7_encode_train = one_hot.transform(train[[\"f7\"]])\n",
    "f7_encode_test = one_hot.transform(test[[\"f7\"]])\n",
    "train.insert(13, \"f7_Maybe\", [f7_encode_train[i][0] for i in range(len(f7_encode_train))])\n",
    "train.insert(14, \"f7_No\", [f7_encode_train[i][1] for i in range(len(f7_encode_train))])\n",
    "train.insert(15, \"f7_Yes\", [f7_encode_train[i][2] for i in range(len(f7_encode_train))])\n",
    "test.insert(13, \"f7_Maybe\", [f7_encode_test[i][0] for i in range(len(f7_encode_test))])\n",
    "test.insert(14, \"f7_No\", [f7_encode_test[i][1] for i in range(len(f7_encode_test))])\n",
    "test.insert(15, \"f7_Yes\", [f7_encode_test[i][2] for i in range(len(f7_encode_test))])\n",
    "\n",
    "# encoding f9\n",
    "# train[\"f9\"] is now the 17th column\n",
    "one_hot.fit(train[[\"f9\"]])\n",
    "f9_encode_train = one_hot.transform(train[[\"f9\"]])\n",
    "f9_encode_test = one_hot.transform(test[[\"f9\"]])\n",
    "train.insert(17, \"f9_X\", [f9_encode_train[i][0] for i in range(len(f9_encode_train))])\n",
    "train.insert(18, \"f9_Y\", [f9_encode_train[i][1] for i in range(len(f9_encode_train))])\n",
    "train.insert(19, \"f9_Z\", [f9_encode_train[i][2] for i in range(len(f9_encode_train))])\n",
    "test.insert(17, \"f9_X\", [f9_encode_test[i][0] for i in range(len(f9_encode_test))])\n",
    "test.insert(18, \"f9_Y\", [f9_encode_test[i][1] for i in range(len(f9_encode_test))])\n",
    "test.insert(19, \"f9_Z\", [f9_encode_test[i][2] for i in range(len(f9_encode_test))])\n",
    "\n",
    "# encoding f16\n",
    "# train[\"f16\"] is now the 21st column\n",
    "one_hot.fit(train[[\"f16\"]])\n",
    "f16_encode_train = one_hot.transform(train[[\"f16\"]])\n",
    "f16_encode_test = one_hot.transform(test[[\"f16\"]])\n",
    "train.insert(21, \"f16_A\", [f16_encode_train[i][0] for i in range(len(f16_encode_train))])\n",
    "train.insert(22, \"f16_B\", [f16_encode_train[i][1] for i in range(len(f16_encode_train))])\n",
    "train.insert(23, \"f16_C\", [f16_encode_train[i][2] for i in range(len(f16_encode_train))])\n",
    "test.insert(21, \"f16_A\", [f16_encode_test[i][0] for i in range(len(f16_encode_test))])\n",
    "test.insert(22, \"f16_B\", [f16_encode_test[i][1] for i in range(len(f16_encode_test))])\n",
    "test.insert(23, \"f16_C\", [f16_encode_test[i][2] for i in range(len(f16_encode_test))])\n",
    "\n",
    "\n",
    "\n",
    "# need to now remove the original string categorical data\n",
    "train = train.drop(columns=[\"f1\", \"f3\", \"f5\", \"f7\", \"f9\", \"f11\", \"f16\"])\n",
    "test = test.drop(columns=[\"f1\", \"f3\", \"f5\", \"f7\", \"f9\", \"f11\", \"f16\"])\n",
    "\n",
    "print(train)\n",
    "\n",
    "# saving encoded train and test data to new csv's\n",
    "train.to_csv(\"enc_train.csv\", index=False)\n",
    "test.to_csv(\"enc_test.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa9f7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e468543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
