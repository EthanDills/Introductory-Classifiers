{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d81448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ae3fc2b",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Some of our data is categorical feature data. This won't work for our models relying on numerical data.\n",
    "Therefore we need to encode these string features into some kind of numerical value.\n",
    "\n",
    "For string data that seems to be ordered, we'll use **[ordinal encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder)** to convey that this information has an order to it.\n",
    "\n",
    "For string data that doesn't seem to be ordered, we'll use **[one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)** so the model doesn't interpret these features as having an order.\n",
    "* Note that OneHotEncoder() by default sorts String categorical features alphabetically\n",
    "\n",
    "\n",
    "\n",
    "### Differentiating Ordered vs Unordered Features\n",
    "\n",
    "**ordered string features: f3, f11**\n",
    "\n",
    "**unordered string features: f1, f5, f7, f9, f16** (some of these could technically be considered ordered... but I didn't think they were)\n",
    "\n",
    "\n",
    "### Observation\n",
    "\n",
    "For the features which are one-hot encoded, we can actually drop one category while keeping the same amount of information!\n",
    "\n",
    "example:\n",
    "```python\n",
    "f1_Bird  | f1_Cat  | f1_Dog\n",
    "   0          1         0\n",
    "   1          0         0\n",
    "   0          0         1\n",
    "\n",
    "becomes\n",
    "\n",
    "f1_Cat  | f1_Dog\n",
    "\n",
    "   1         0\n",
    "   0         0\n",
    "   0         1\n",
    "```\n",
    "Then in the second row, this would imply that f1_Bird is 1. This allows us to delete 5 of the one-hot encoded features!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb0664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     f1_Cat  f1_Dog   f2  f3  f4  f5_Green  f5_Red   f6  f7_No  f7_Yes  ...  \\\n",
      "0       1.0     0.0  0.6   0   4       0.0     0.0 -2.1    0.0     1.0  ...   \n",
      "1       1.0     0.0 -0.6   2   2       1.0     0.0 -2.2    0.0     0.0  ...   \n",
      "2       0.0     1.0 -0.6   1   3       0.0     1.0 -1.4    0.0     0.0  ...   \n",
      "3       1.0     0.0  0.7   0   1       1.0     0.0 -1.9    1.0     0.0  ...   \n",
      "4       0.0     1.0  1.4   1   4       0.0     1.0 -2.4    1.0     0.0  ...   \n",
      "..      ...     ...  ...  ..  ..       ...     ...  ...    ...     ...  ...   \n",
      "995     1.0     0.0 -0.0   1   1       1.0     0.0 -1.1    1.0     0.0  ...   \n",
      "996     1.0     0.0 -0.6   2   3       0.0     0.0 -1.1    1.0     0.0  ...   \n",
      "997     0.0     1.0 -0.3   0   4       1.0     0.0 -2.9    0.0     1.0  ...   \n",
      "998     0.0     1.0  1.5   0   4       0.0     0.0 -2.2    0.0     0.0  ...   \n",
      "999     0.0     0.0 -1.6   2   2       0.0     1.0 -1.7    0.0     1.0  ...   \n",
      "\n",
      "     f11  f12  f13  f14  f15  f17  f18  f19  f20  target  \n",
      "0      2  6.6  0.5  1.2    1 -0.0 -1.7 -1.5  1.2       0  \n",
      "1      1  3.9 -0.1 -0.1    1 -0.2 -1.6 -0.3  2.4       1  \n",
      "2      2  3.4  0.6 -0.1    0 -0.7  0.9  0.1  2.4       1  \n",
      "3      1  5.0  1.5  0.7    1  0.5 -2.0  1.0  5.0       1  \n",
      "4      0  4.7 -0.2 -1.1    0 -1.5  1.0  0.5  2.9       1  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...     ...  \n",
      "995    1  6.6 -0.3  0.8    1  1.9  0.9 -2.4  2.9       0  \n",
      "996    1  4.4  1.8 -0.6    0  0.2 -0.6 -0.0  4.8       0  \n",
      "997    2  4.4  0.6  2.0    0 -0.7 -1.8  0.5  3.0       0  \n",
      "998    2  6.6 -0.6  0.1    0 -0.2  1.9  0.5  2.4       0  \n",
      "999    0  5.7  0.6 -1.2    0  0.4 -0.8  0.6  4.6       1  \n",
      "\n",
      "[1000 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_for_students.csv\")\n",
    "test = pd.read_csv(\"test_for_students.csv\")\n",
    "\n",
    "\n",
    "# manually doing ordinal encoding for f3, f11\n",
    "f3_mapping = {\"Low\":0, \"Medium\":1, \"High\":2}\n",
    "train[\"f3\"] = train[\"f3\"].map(f3_mapping)\n",
    "test[\"f3\"] = test[\"f3\"].map(f3_mapping)\n",
    "\n",
    "f11_mapping = {\"Basic\":0, \"Standard\":1, \"Premium\":2}\n",
    "train[\"f11\"] = train[\"f11\"].map(f11_mapping)\n",
    "test[\"f11\"] = test[\"f11\"].map(f11_mapping)\n",
    "# print(train[\"f11\"])\n",
    "\n",
    "\n",
    "# Implementing one-hot encoding with sklearn for f1, f5, f7, f9, f16\n",
    "# NOTE: for however many categories there are in a feature (for example, f1 has 3 categories: Bird, Cat, Dog),\n",
    "#  We'll need to add this amount of columns. For example, f1 gets turned into 3 feature columns after one-hot encoding\n",
    "one_hot = OneHotEncoder(sparse_output=False)\n",
    "    \n",
    "# print(train[\"f1\"])\n",
    "\n",
    "\n",
    "# encoding f1\n",
    "one_hot.fit(train[[\"f1\"]])\n",
    "f1_encode_train = one_hot.transform(train[[\"f1\"]])\n",
    "f1_encode_test = one_hot.transform(test[[\"f1\"]])\n",
    "# f1_Bird_col = [f1_encode[i][0] for i in range(len(f1_encode))]\n",
    "# print(f1_Bird_col)\n",
    "train.insert(1, \"f1_Bird\", [f1_encode_train[i][0] for i in range(len(f1_encode_train))])\n",
    "train.insert(2, \"f1_Cat\", [f1_encode_train[i][1] for i in range(len(f1_encode_train))])\n",
    "train.insert(3, \"f1_Dog\", [f1_encode_train[i][2] for i in range(len(f1_encode_train))])\n",
    "test.insert(1, \"f1_Bird\", [f1_encode_test[i][0] for i in range(len(f1_encode_test))])\n",
    "test.insert(2, \"f1_Cat\", [f1_encode_test[i][1] for i in range(len(f1_encode_test))])\n",
    "test.insert(3, \"f1_Dog\", [f1_encode_test[i][2] for i in range(len(f1_encode_test))])\n",
    "\n",
    "# encoding f5\n",
    "# train[\"f5\"] is now the eighth column\n",
    "one_hot.fit(train[[\"f5\"]])\n",
    "f5_encode_train = one_hot.transform(train[[\"f5\"]])\n",
    "f5_encode_test = one_hot.transform(test[[\"f5\"]])\n",
    "\n",
    "train.insert(8, \"f5_Blue\", [f5_encode_train[i][0] for i in range(len(f5_encode_train))])\n",
    "train.insert(9, \"f5_Green\", [f5_encode_train[i][1] for i in range(len(f5_encode_train))])\n",
    "train.insert(10, \"f5_Red\", [f5_encode_train[i][2] for i in range(len(f5_encode_train))])    \n",
    "test.insert(8, \"f5_Blue\", [f5_encode_test[i][0] for i in range(len(f5_encode_test))])\n",
    "test.insert(9, \"f5_Green\", [f5_encode_test[i][1] for i in range(len(f5_encode_test))])\n",
    "test.insert(10, \"f5_Red\", [f5_encode_test[i][2] for i in range(len(f5_encode_test))])    \n",
    "\n",
    "# encoding f7\n",
    "# train[\"f7\"] is now the 13th column\n",
    "one_hot.fit(train[[\"f7\"]]) \n",
    "f7_encode_train = one_hot.transform(train[[\"f7\"]])\n",
    "f7_encode_test = one_hot.transform(test[[\"f7\"]])\n",
    "train.insert(13, \"f7_Maybe\", [f7_encode_train[i][0] for i in range(len(f7_encode_train))])\n",
    "train.insert(14, \"f7_No\", [f7_encode_train[i][1] for i in range(len(f7_encode_train))])\n",
    "train.insert(15, \"f7_Yes\", [f7_encode_train[i][2] for i in range(len(f7_encode_train))])\n",
    "test.insert(13, \"f7_Maybe\", [f7_encode_test[i][0] for i in range(len(f7_encode_test))])\n",
    "test.insert(14, \"f7_No\", [f7_encode_test[i][1] for i in range(len(f7_encode_test))])\n",
    "test.insert(15, \"f7_Yes\", [f7_encode_test[i][2] for i in range(len(f7_encode_test))])\n",
    "\n",
    "# encoding f9\n",
    "# train[\"f9\"] is now the 17th column\n",
    "one_hot.fit(train[[\"f9\"]])\n",
    "f9_encode_train = one_hot.transform(train[[\"f9\"]])\n",
    "f9_encode_test = one_hot.transform(test[[\"f9\"]])\n",
    "train.insert(17, \"f9_X\", [f9_encode_train[i][0] for i in range(len(f9_encode_train))])\n",
    "train.insert(18, \"f9_Y\", [f9_encode_train[i][1] for i in range(len(f9_encode_train))])\n",
    "train.insert(19, \"f9_Z\", [f9_encode_train[i][2] for i in range(len(f9_encode_train))])\n",
    "test.insert(17, \"f9_X\", [f9_encode_test[i][0] for i in range(len(f9_encode_test))])\n",
    "test.insert(18, \"f9_Y\", [f9_encode_test[i][1] for i in range(len(f9_encode_test))])\n",
    "test.insert(19, \"f9_Z\", [f9_encode_test[i][2] for i in range(len(f9_encode_test))])\n",
    "\n",
    "# encoding f16\n",
    "# train[\"f16\"] is now the 21st column\n",
    "one_hot.fit(train[[\"f16\"]])\n",
    "f16_encode_train = one_hot.transform(train[[\"f16\"]])\n",
    "f16_encode_test = one_hot.transform(test[[\"f16\"]])\n",
    "train.insert(21, \"f16_A\", [f16_encode_train[i][0] for i in range(len(f16_encode_train))])\n",
    "train.insert(22, \"f16_B\", [f16_encode_train[i][1] for i in range(len(f16_encode_train))])\n",
    "train.insert(23, \"f16_C\", [f16_encode_train[i][2] for i in range(len(f16_encode_train))])\n",
    "test.insert(21, \"f16_A\", [f16_encode_test[i][0] for i in range(len(f16_encode_test))])\n",
    "test.insert(22, \"f16_B\", [f16_encode_test[i][1] for i in range(len(f16_encode_test))])\n",
    "test.insert(23, \"f16_C\", [f16_encode_test[i][2] for i in range(len(f16_encode_test))])\n",
    "\n",
    "\n",
    "\n",
    "# need to now remove the original string categorical data\n",
    "train = train.drop(columns=[\"f1\", \"f5\", \"f7\", \"f9\", \"f16\"])\n",
    "test = test.drop(columns=[\"f1\", \"f5\", \"f7\", \"f9\", \"f16\"])\n",
    "\n",
    "# now removing a single category feature from each one-hot encoded feature.\n",
    "train = train.drop(columns=[\"f1_Bird\", \"f5_Blue\", \"f7_Maybe\", \"f9_X\", \"f16_A\"])\n",
    "test = test.drop(columns=[\"f1_Bird\", \"f5_Blue\", \"f7_Maybe\", \"f9_X\", \"f16_A\"])\n",
    "\n",
    "print(train)\n",
    "\n",
    "# saving encoded train and test data to new csv's\n",
    "train.to_csv(\"enc_train.csv\", index=False)\n",
    "test.to_csv(\"enc_test.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa9f7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e468543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
